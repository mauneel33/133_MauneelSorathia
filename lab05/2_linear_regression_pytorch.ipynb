{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "2-linear-regression-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "v0BtAX1--7l_"
      },
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecc6e79cdfb6a8ca882895ccc895b61b960b0a04",
        "id": "i1HSrBDb-7t9"
      },
      "source": [
        "## Linear Regression Model using PyTorch built-ins\n",
        "\n",
        "Let's re-implement the same model using some built-in functions and classes from PyTorch.\n",
        "\n",
        "And now using two different targets: Apples and Oranges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ce66cf0d09a3f38bf2f00ea40418c56d98f1f814",
        "id": "iXiEK54j-7t-"
      },
      "source": [
        "# Imports\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "74bb18bd01ac809079eeb8d05695206e8ba02069",
        "id": "wCsxgTWO-7uM"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d94b355f55250e9c7dcff668920f02d7c5c04925",
        "id": "nJRlm4-N-7uY"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a0665466eb5401f40a816b323a34450b2c052c41",
        "id": "O6JT5Ng6-7uj"
      },
      "source": [
        "### Dataset and DataLoader\n",
        "\n",
        "We'll create a `TensorDataset`, which allows access to rows from `inputs` and `targets` as tuples. We'll also create a DataLoader, to split the data into batches while training. It also provides other utilities like shuffling and sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "206f5fd0473386476b23477bf38d2c327b6376c9",
        "id": "iGYdbuWc-7ul"
      },
      "source": [
        "# Import tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "c47a4f2f86fda3918094e01cf7ab0698bbb5acc7",
        "id": "LY_cq6Bf-7ux"
      },
      "source": [
        "# Define dataset\n",
        "dataset = torch.utils.data.TensorDataset(inputs, targets)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0a2f69126319d738b82ae67d5d404ecd6161bfac",
        "id": "I-_dMpco-7u-"
      },
      "source": [
        "# Define data loader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "276a262e1b9e3a048bcd32989013f9c501c59037",
        "id": "Dq8gUbVx-7vK"
      },
      "source": [
        "### nn.Linear\n",
        "Instead of initializing the weights & biases manually, we can define the model using `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "59da3506559a0640d80d18f77b02726a1757be2f",
        "id": "sKa873ZD-7vN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbedc5dd-b767-4802-8214-81c7f4b5501b"
      },
      "source": [
        "# Define model\n",
        "model = nn.Linear(inputs.shape[1], targets.shape[1])\n",
        "model.parameters()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f551d390e50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b3a4a8c499a4680f2533329712de034671dd1cdd",
        "id": "rku14lz3-7vX"
      },
      "source": [
        "### Optimizer\n",
        "Instead of manually manipulating the weights & biases using gradients, we can use the optimizer `optim.SGD`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1848398bd1ced8c25a7bb55612cf32a774500280",
        "id": "Yd4H-T8g-7va"
      },
      "source": [
        "# Define optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "28cbe62be55010bd11b31d819cff38da5a772b18",
        "id": "V2ktEA-C-7vl"
      },
      "source": [
        "### Loss Function\n",
        "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "69d7f4e8e27ccd077f711da27f8bede8aa711893",
        "id": "TF2xmzgO-7vo"
      },
      "source": [
        "# Import nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a02ff888ed4be720fd9ca376022d8fdcf2559683",
        "id": "hSgxvr8N-7vz"
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a540adf76725ea9968025f6c029fdd251bdada6c",
        "id": "9vyVL5io-7wA"
      },
      "source": [
        "#loss = loss_fn(? , ?)\n",
        "#print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e833614a69ff18c554a3d89f643ae2f11e0260f6",
        "id": "9jbPdkiO-7wM"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We are ready to train the model now. We can define a utility function `fit` which trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "128bc7260221f5338edf8b503c75f0c7d1cce7e8",
        "id": "zDnWui7g-7wP"
      },
      "source": [
        "# Define a utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt):\n",
        "  for epoch in range(num_epochs):\n",
        "    for xb,yb in dataloader:\n",
        "      # Generate predictions\n",
        "      pred = model(xb)\n",
        "      loss = loss_fn(yb,pred)\n",
        "      # Perform gradient descent\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "      print('Training loss: ', loss_fn(model(inputs), targets))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ae8ca4686cf6a68f6c9ca93bf3d227abe96c2201",
        "id": "Gd8tiT_q-7wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe069adb-b807-4781-aa8b-aed9a56894a0"
      },
      "source": [
        "# Train the model for 100 epochs\n",
        "fit(120 , model , loss_fn, optimizer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  tensor(8113.3325, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5154.9639, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3294.7192, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2122.6189, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1382.0375, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(912.3070, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(612.8047, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(420.4847, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(295.8214, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(214.0140, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(159.4824, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(122.4223, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(96.6505, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(78.2548, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(64.7494, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(54.5452, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(46.6187, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(40.3035, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(35.1597, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(30.8924, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(27.2995, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(24.2389, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(21.6085, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(19.3324, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(17.3528, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(15.6243, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(14.1106, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(12.7819, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(11.6135, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(10.5843, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(9.6766, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(8.8750, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(8.1663, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(7.5389, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.9830, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.4897, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.0514, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.6615, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.3140, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.0039, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.7267, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.4784, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.2556, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.0552, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.8746, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.7114, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.5637, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.4295, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.3073, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.1958, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.0936, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.9997, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.9133, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.8333, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.7592, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.6903, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.6260, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.5658, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.5093, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.4561, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.4059, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.3584, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.3132, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.2703, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.2293, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.1900, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.1524, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.1164, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.0816, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.0482, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.0158, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.9846, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.9543, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.9250, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8965, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8689, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8420, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8158, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7903, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7654, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7411, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7174, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6943, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6717, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6495, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6279, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6068, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5860, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5658, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5459, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5265, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5074, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4888, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4705, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4526, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4350, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4178, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4009, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3843, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3681, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3521, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3365, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3212, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3061, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2914, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2769, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2627, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2488, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2351, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2217, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2085, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1956, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1830, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1705, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1583, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1464, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1346, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1231, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1118, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1007, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0898, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0791, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0686, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0583, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0482, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0383, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0285, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0190, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0096, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0004, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9914, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9825, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9738, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9653, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9569, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9487, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9406, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9327, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9250, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9173, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9099, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.9025, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8953, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8882, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8813, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8745, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8678, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8612, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8548, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8485, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8423, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8362, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8302, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8243, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8186, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8129, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8074, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.8020, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7966, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7914, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7862, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7812, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7762, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7714, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7666, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7619, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7573, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7528, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7484, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7441, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7398, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7356, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7315, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7275, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7235, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7196, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7158, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7121, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7084, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7048, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.7013, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6978, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6944, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6911, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6878, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6846, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6814, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6783, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6753, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6723, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6694, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6665, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6637, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6609, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6582, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6555, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6529, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6503, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6478, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6453, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6429, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6405, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6382, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6359, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6336, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6314, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6293, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6271, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6250, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6230, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6210, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6190, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6171, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6152, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6133, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6115, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6097, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6079, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6062, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6045, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6028, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.6012, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5996, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5980, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5964, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5949, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5934, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5920, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5905, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5891, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5877, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5864, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5850, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5837, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5825, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5812, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5800, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5787, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5775, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5764, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5752, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5741, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5730, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5719, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5709, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5698, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5688, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5678, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5668, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5658, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5649, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5639, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5630, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5621, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5613, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5604, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5595, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5587, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5579, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5571, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5563, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5555, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5548, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5540, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5533, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5526, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5519, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5512, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5505, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5498, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5492, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5485, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5479, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5473, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5467, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5461, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5455, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5449, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5444, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5438, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5433, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5427, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5422, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5417, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5412, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5407, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5402, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5398, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5393, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5388, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5384, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5379, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5375, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5371, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5367, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5363, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5359, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5355, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5351, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5347, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5343, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5340, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5336, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5333, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5329, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5326, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5322, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5319, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5316, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5313, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5310, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5307, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5304, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5301, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5298, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5295, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5292, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5290, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5287, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5284, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5282, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5279, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5277, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5274, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5272, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5270, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5267, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5265, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5263, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5261, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5259, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5257, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5255, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5253, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5251, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5249, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5247, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5245, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5243, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5241, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5240, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5238, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5236, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5234, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5233, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5231, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5230, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5228, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5227, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5225, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5224, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5222, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5221, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5219, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5218, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5217, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5215, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5214, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5213, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(0.5212, grad_fn=<MseLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "32588a47d0478772a1f08fa55874a322630bd0b6",
        "id": "c3Bf-Emn-7wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df68ad04-f34e-4fea-997d-2c53c3807e93"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.0777,  70.3703],\n",
              "        [ 82.2895, 100.5627],\n",
              "        [118.6441, 133.1053],\n",
              "        [ 21.0746,  37.0522],\n",
              "        [101.9694, 118.9911],\n",
              "        [ 57.0777,  70.3703],\n",
              "        [ 82.2895, 100.5627],\n",
              "        [118.6441, 133.1053],\n",
              "        [ 21.0746,  37.0522],\n",
              "        [101.9694, 118.9911],\n",
              "        [ 57.0777,  70.3703],\n",
              "        [ 82.2895, 100.5627],\n",
              "        [118.6441, 133.1053],\n",
              "        [ 21.0746,  37.0522],\n",
              "        [101.9694, 118.9911]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "12d757c0f37c2e3af65cf9d4b59878cc10c65acf",
        "id": "_gDGmiHl-7wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98cf023e-f176-4722-bdf7-198bda37b49e"
      },
      "source": [
        "# Compare with targets\n",
        "targets"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2448d9832722f4f2813f8bd80b91daefd901dc2e",
        "id": "b9nvUidI-7xD"
      },
      "source": [
        "Now we can define the model, optimizer and loss function exactly as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAyCq48TMlWJ"
      },
      "source": [
        "#Exercise 1:\n",
        " Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)\n",
        "#Exercise 2:\n",
        " Try Linear regression on same prediction data using Tensorflow\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5JWwFdJr510"
      },
      "source": [
        "**Exercise 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRKXGLZkr5OL",
        "outputId": "406e0a86-66d7-4445-d072-78c269fcdb3b"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(inputs, targets, test_size=0.4, random_state=133)\n",
        "lr.fit(X_train, Y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feQVslZPsVdP",
        "outputId": "9799534a-d268-42f9-9b6a-de7ea77be999"
      },
      "source": [
        "predicted = lr.predict(X_test)\n",
        "print(predicted)\n",
        "print(Y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[118.481804 133.03632 ]\n",
            " [ 56.878216  69.938446]\n",
            " [101.8928   119.0776  ]\n",
            " [ 21.12847   37.061092]\n",
            " [ 82.359604 100.90471 ]\n",
            " [118.481804 133.03632 ]]\n",
            "tensor([[119., 133.],\n",
            "        [ 56.,  70.],\n",
            "        [103., 119.],\n",
            "        [ 22.,  37.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuHBAymTsp3w"
      },
      "source": [
        "**Exercise 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2r-uijsrsD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMYmqqECta6y",
        "outputId": "17fe9f3e-cce1-4fc4-fa89-de9e3158c3e7"
      },
      "source": [
        "inputs = tf.Variable(inputs)\n",
        "targets = tf.Variable(targets)\n",
        "targets"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(15, 2) dtype=float32, numpy=\n",
              "array([[ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A37XqirrtqfM"
      },
      "source": [
        "v = np.array([[34, 12], [90,43], [54, 30]], dtype='float32')\n",
        "r = np.array([43, 21], dtype='float32')\n",
        "v = tf.Variable(v)\n",
        "r = tf.Variable(r)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTcNq8hruFcK",
        "outputId": "ced3d55f-9a49-4f5d-be06-52f3917cb17d"
      },
      "source": [
        "predicted = inputs@v+r\n",
        "print(meanse(predicted, targets))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(116286070.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDqB6_BSxEhU",
        "outputId": "d190df2a-74a4-408c-8fb7-31a4fc86d973"
      },
      "source": [
        "def model(m):\n",
        "  return m@v+r\n",
        "def meanse(a, b):\n",
        "  return tf.reduce_mean(tf.square(a - b))\n",
        "print(meanse(predicted, targets))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(116286070.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9CJFdRMxUzK"
      },
      "source": [
        "epochs = 100\n",
        "for i in range(epochs):\n",
        "  with tf.GradientTape(persistent=True) as t:\n",
        "    closs = meanse(targets, model(inputs))\n",
        "  v1 = t.gradient(closs, v)\n",
        "  r1 = t.gradient(closs, r)\n",
        "\n",
        "  v.assign_sub(1e-4*v1)\n",
        "  r.assign_sub(1e-4*r1)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3aEHj9tx-dP",
        "outputId": "6dacf0ae-cb3c-496c-afa4-fbb3d375a65b"
      },
      "source": [
        "model(inputs)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 2), dtype=float32, numpy=\n",
              "array([[ 60.925423,  70.77222 ],\n",
              "       [102.03048 , 121.62281 ],\n",
              "       [ 67.69624 ,  84.62628 ],\n",
              "       [  3.445816,  21.62906 ],\n",
              "       [155.0615  , 168.65588 ],\n",
              "       [ 60.925423,  70.77222 ],\n",
              "       [102.03048 , 121.62281 ],\n",
              "       [ 67.69624 ,  84.62628 ],\n",
              "       [  3.445816,  21.62906 ],\n",
              "       [155.0615  , 168.65588 ],\n",
              "       [ 60.925423,  70.77222 ],\n",
              "       [102.03048 , 121.62281 ],\n",
              "       [ 67.69624 ,  84.62628 ],\n",
              "       [  3.445816,  21.62906 ],\n",
              "       [155.0615  , 168.65588 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRAPFBP9yCy0",
        "outputId": "c3a3d74c-f032-49d0-9293-0e9c8d2c11f9"
      },
      "source": [
        "targets"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(15, 2) dtype=float32, numpy=\n",
              "array([[ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}